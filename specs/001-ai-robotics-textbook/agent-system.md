# Agent System Design: AI-Native Textbook Chatbot

**Feature Branch**: `001-ai-robotics-textbook`  
**Created**: December 4, 2025  
**Spec**: [specs/001-ai-robotics-textbook/spec.md](specs/001-ai-robotics-textbook/spec.md)
**Plan**: [specs/001-ai-robotics-textbook/plan.md](specs/001-ai-robotics-textbook/plan.md)
**Research**: [specs/001-ai-robotics-textbook/research.md](specs/001-ai-robotics-textbook/research.md)
**Data Model**: [specs/001-ai-robotics-textbook/data-model.md](specs/001-ai-robotics-textbook/data-model.md)

## Overview

The agent system is the core intelligence behind the interactive RAG chatbot, orchestrating interactions through the OpenAI Agent SDK with Gemini as the primary LLM. It comprises several specialized agents, each with distinct roles, tools, memory management, and deterministic fallback behaviors.

## Agent Layer Architecture

The agent system will follow a modular architecture, where a main orchestrator agent dispatches tasks to specialized sub-agents.

### 1. Retrieval Agent (RAG Orchestration)

*   **Role**: Responsible for retrieving relevant information from the vectorized textbook content based on user queries. It acts as the primary interface to the Qdrant vector store.
*   **Tools**:
    *   `vector_search(query: str, filters: dict = None, limit: int = 5) -> List[TextChunk]`: Searches Qdrant for text chunks similar to the query. Filters can include chapter ID, section ID, etc.
    *   `get_chapter_content(chapter_id: str, section_id: str) -> Text`: Retrieves the full markdown content of a specific chapter/section.
*   **Memory Scope**: Short-term session memory for conversational context (e.g., previous turns in a conversation).
*   **Failure Behavior**:
    *   If no relevant chunks are found: Return a predefined "no relevant information found" message.
    *   If Qdrant service is unavailable: Fallback to a message indicating retrieval service is down.

### 2. Verification Agent (Anti-Hallucination & Citation Checks)

*   **Role**: Ensures that the information generated by the LLM is accurate, directly supported by the retrieved textbook content, and provides correct citations. Prevents hallucinations.
*   **Tools**:
    *   `verify_citation(generated_text: str, source_chunks: List[TextChunk]) -> bool`: Checks if `generated_text` is directly derivable from `source_chunks`.
    *   `extract_citation_details(source_chunks: List[TextChunk]) -> Dict`: Extracts chapter and section IDs from verified source chunks.
*   **Memory Scope**: Short-term (per-response context: generated text, retrieved chunks).
*   **Failure Behavior**:
    *   If verification fails (hallucination detected or citation not found): Request the Explanation Agent to rephrase or state that the information cannot be verified from the book.
    *   If source chunks are insufficient: Flag for human review or request more context from Retrieval Agent.

### 3. Explanation Agent (Pedagogical Response Generation)

*   **Role**: Takes verified information and formats it into a pedagogically sound, clear, and concise response tailored to the student's learning profile (if personalization is enabled).
*   **Tools**:
    *   `generate_pedagogical_response(verified_info: str, student_profile: dict = None) -> str`: Formulates the final response, adapting tone and depth based on `student_profile`.
    *   `rephrase_for_clarity(text: str, complexity_level: str) -> str`: Rewrites text to match a target complexity level.
*   **Memory Scope**: Short-term session memory for consistent tone and context. Also accesses `Student`'s `personalization_settings`.
*   **Failure Behavior**:
    *   If response generation is unclear or too complex: Re-attempt with a simpler request to the LLM.
    *   If LLM quota exceeded: Generate a fallback response using pre-defined templates, stating LLM is unavailable.

### 4. Assessment Agent (Quiz, Grading, Feedback)

*   **Role**: Generates quizzes, assesses student answers, and provides constructive feedback based on textbook content.
*   **Tools**:
    *   `generate_quiz(chapter_id: str, num_questions: int, difficulty: str) -> List[Question]`: Creates quiz questions based on specific chapter content.
    *   `assess_answer(question: Question, student_answer: str) -> Feedback`: Grades a student's response and provides tailored feedback.
    *   `get_assessment_summary(student_id: str) -> Report`: Provides a summary of a student's performance.
*   **Memory Scope**: Session memory (for ongoing quizzes). Accesses `Assessment` data.
*   **Failure Behavior**:
    *   If quiz generation fails: Provide a generic message about not being able to generate a quiz.
    *   If assessment logic fails: Provide a default "cannot assess at this time" message.

### 5. Safety & Refusal Agent (Unsafe Prompt Filtering)

*   **Role**: Filters out unsafe, malicious, or out-of-scope queries. Ensures adherence to ethical guidelines and project constraints.
*   **Tools**:
    *   `classify_query_safety(query: str) -> SafetyRating`: Classifies query for safety (e.g., weapons, self-harm, hate speech).
    *   `check_scope(query: str, textbook_scope: List[str]) -> bool`: Determines if a query is within the defined textbook scope.
*   **Memory Scope**: None (stateless, per-query evaluation).
*   **Failure Behavior**:
    *   If query is unsafe or out-of-scope: Immediately return a polite refusal message to the user, explaining why the query cannot be answered.
    *   If classification tool fails: Default to a conservative "cannot process this query" message.

## Agent Interaction Flow (Example: User Query)

1.  **User Query** received by FastAPI backend.
2.  **Safety & Refusal Agent**: First pass to check for unsafe/out-of-scope content.
    *   If unsafe/out-of-scope, return refusal.
3.  **Retrieval Agent**: If safe, retrieve relevant chunks from Qdrant based on query and context (e.g., selected text).
4.  **Verification Agent**: Verify the retrieved chunks can answer the query.
5.  **Explanation Agent**: Formulate an initial response using Gemini LLM.
6.  **Verification Agent**: Re-verify the LLM's generated response against source chunks for accuracy and hallucination. Check for mandatory citation.
    *   If verification fails, Explanation Agent is prompted to rephrase or generate a refusal.
7.  **Final Response** (with citation) returned to user.

## Deterministic Fallback for Quota Exceeded

If the Gemini LLM quota is exceeded during any agent's operation:
*   The system will detect the API error.
*   The relevant agent will trigger a pre-defined fallback mechanism.
*   For Explanation Agent: Generate a templated response stating, "I'm currently experiencing high demand and cannot provide a detailed response. Please try again later or refer directly to the textbook."
*   For other agents: Log the event and inform the user of temporary service unavailability or redirect to static content.
