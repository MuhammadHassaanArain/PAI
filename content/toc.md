# Table of Contents: AI-Native Textbook on Physical AI & Humanoid Robotics

This Table of Contents (TOC) outlines the structure of the textbook, organized into modules and chapters. Each chapter will follow a standardized template including learning objectives, core concepts, step-by-step labs, code examples, hardware/cloud alternatives, safety notes, summaries, assessments, and agent interaction examples.

## Section 0: Foundations of Physical AI

*   **Chapter 0.1**: Introduction to Physical AI and Embodied Intelligence
*   **Chapter 0.2**: Core Concepts of Robotics and AI for Physical Systems
*   **Chapter 0.3**: Ethics and Safety in Humanoid Robotics

## Section 1: ROS 2 – Robotic Nervous System

*   **Chapter 1.1**: ROS 2 Fundamentals: Nodes, Topics, Services, Actions
*   **Chapter 1.2**: ROS 2 Packages and Workspace Management
*   **Chapter 1.3**: Advanced ROS 2 Communication Patterns
*   **Lab 1.1**: Basic ROS 2 Publisher/Subscriber in Python

## Section 2: Digital Twin – Gazebo & Unity

*   **Chapter 2.1**: Introduction to Robot Simulation with Gazebo
*   **Chapter 2.2**: URDF: Robot Modeling for Simulation
*   **Chapter 2.3**: Integrating ROS 2 with Gazebo Simulations
*   **Lab 2.1**: Creating a Basic URDF Model and Simulating in Gazebo
*   **Chapter 2.4**: Unity for Advanced Robot Visualization and Interaction
*   **Lab 2.2**: ROS 2 and Gazebo to Unity Visualization Pipeline

## Section 3: AI Brain – NVIDIA Isaac

*   **Chapter 3.1**: Introduction to NVIDIA Omniverse and Isaac Sim
*   **Chapter 3.2**: Isaac Sim for Realistic Robotics Simulation and Synthetic Data Generation
*   **Chapter 3.3**: Isaac ROS: Accelerated Perception for Robotics
*   **Lab 3.1**: Basic Perception Pipeline with Isaac ROS
*   **Chapter 3.4**: Deploying Isaac ROS Pipelines to Edge Devices (Jetson)
*   **Lab 3.2**: Sim-to-Edge Inference Deployment

## Section 4: Vision-Language-Action Systems

*   **Chapter 4.1**: Voice Interfaces for Robotics: Speech-to-ROS 2 Commands
*   **Chapter 4.2**: Large Language Models for Cognitive Robot Planning (Agent-Controlled)
*   **Chapter 4.3**: Multimodal VLA: Integrating Vision, Language, and Action
*   **Lab 4.1**: Voice Control of a Simulated Robot Arm
*   **Lab 4.2**: LLM-driven Task Planning for Robot Actuation

## Section 5: Capstone – Autonomous Humanoid

*   **Chapter 5.1**: Capstone Project Architecture: Integrating VLA with Humanoid Control
*   **Chapter 5.2**: Capstone Project Implementation: Building a Conversational Humanoid Robot
*   **Lab 5.1**: Full Humanoid Robot Control in Simulation

## Section 6: Cloud vs On-Prem Lab Setup

*   **Chapter 6.1**: Local Workstation Setup Guide for Robotics Development
*   **Chapter 6.2**: Cloud GPU Environment Setup for Robotics (AWS, GCP, Azure)

## Section 7: Safety, Ethics & Responsible Deployment

*   **Chapter 7.1**: Advanced Robotics Safety Protocols
*   **Chapter 7.2**: Ethical Considerations in Autonomous Systems
*   **Chapter 7.3**: Responsible Deployment and Human-Robot Interaction

## Section 8: Agentic AI for Robotics Learning

*   **Chapter 8.1**: Introduction to OpenAI Agent SDK for Robotics
*   **Chapter 8.2**: Designing and Implementing Agentic RAG Chatbots for Education
*   **Chapter 8.3**: Agent-Based Assessment and Personalized Learning
*   **Lab 8.1**: Building a Simple RAG Agent
*   **Lab 8.2**: Customizing Agent Behavior for Educational Contexts
